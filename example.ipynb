{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dae68ac",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "初识Taichi，使用Taichi筛素数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a70f427a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] Starting on arch=x64\n",
      "78498\n",
      "=========================================================================\n",
      "Kernel Profiler(count, default) @ X64 \n",
      "=========================================================================\n",
      "[      %     total   count |      min       avg       max   ] Kernel name\n",
      "-------------------------------------------------------------------------\n",
      "[ 99.96%   0.015 s      1x |   14.851    14.851    14.851 ms] count_primes_c92_0_kernel_2_range_for\n",
      "[  0.04%   0.000 s      1x |    0.006     0.006     0.006 ms] count_primes_c92_0_kernel_0_serial\n",
      "[  0.00%   0.000 s      1x |    0.000     0.000     0.000 ms] count_primes_c92_0_kernel_1_serial\n",
      "-------------------------------------------------------------------------\n",
      "[100.00%] Total execution time:   0.015 s   number of results: 3\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "import taichi as ti\n",
    "import time\n",
    "ti.init(arch=ti.cpu, kernel_profiler=True)\n",
    "@ti.func\n",
    "def is_prime(n: int):\n",
    "   result = True\n",
    "   for k in range(2, int(n ** 0.5) + 1):\n",
    "       if n % k == 0:\n",
    "           result = False\n",
    "           break\n",
    "   return result\n",
    "@ti.kernel\n",
    "def count_primes(n: int) -> int:\n",
    "   count = 0\n",
    "   for k in range(2, n):\n",
    "       if is_prime(k):\n",
    "           count += 1\n",
    "   return count\n",
    "#start_time = time.time()\n",
    "print(count_primes(1000000))\n",
    "# Taichi 1000000\n",
    "#    CPU 0.015s\n",
    "#    GPU 0.025s\n",
    "# Python 1000000\n",
    "#    CPU 3.48s\n",
    "#print(time.time()-start_time)\n",
    "ti.profiler.print_kernel_profiler_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b0c111",
   "metadata": {},
   "source": [
    "### Example2\n",
    "AOS vs SOA\n",
    "1. 如果有一些操作只用到属性的子集（比如说x, y, z 而没有 w），那么 SOA 的内存布局可以完全不浪费 w 造成的内存带宽。\n",
    "\n",
    "    注：这里要注意的是 CPU 上的 cacheline 大小是 64B、(NVIDIA) GPU 上是128 B，内存带宽的瓶颈往往是 last-level cache (LLC，比如 CPU 上的 L3 cache、GPU 上的 L2 cache) 到 main memory（也就是内存条）的 bandwidth。LLC 到 main memory 的单位是 cacheline (而不是 byte)。如果一个 cacheline 只用一部分，就会导致 main memory bandwidth 的浪费。在 AOS 的 data layout 下，由于一个粒子的 x, y, z, w 总是在同一个 cacheline 内，没有办法只向 main memory fetch 其中的一部分。后续的会有图片来说明这一点。\n",
    "\n",
    "2. 在 GPU 上，SOA 能够发挥 GPU 硬件的 Coalescing 机制，硬件会把一个 warp （32 个 thread）的数据访问打包成一个 memory transaction，提高效率。类似地，在 CPU 上，SOA 对于 SIMD 模式的编程也更加友好（如 x86 架构下可以使用 _mm_load_ps 等 SIMD intrinsics 对数据进行向量化加载）。\n",
    "\n",
    "3. SOA 的另一个好处是比较容易在运行时给一组数据添加一个 attribute，并且保持访问的高效。本文就不针对这一点展开了。\n",
    "抄自：https://zhuanlan.zhihu.com/p/552884861（强烈推荐大家学习原文章）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e04b126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] Starting on arch=x64\n",
      "=========================================================================\n",
      "Kernel Profiler(count, default) @ X64 \n",
      "=========================================================================\n",
      "[      %     total   count |      min       avg       max   ] Kernel name\n",
      "-------------------------------------------------------------------------\n",
      "[ 92.28%  14.119 s     30x |  466.911   470.618   496.956 ms] assign_all_random_c110_0_kernel_0_range_for\n",
      "[  4.54%   0.695 s     30x |   22.311    23.173    34.396 ms] assign_all_c106_0_kernel_0_range_for\n",
      "[  3.18%   0.486 s     30x |   15.961    16.193    17.635 ms] assign_single_c108_0_kernel_0_range_for\n",
      "-------------------------------------------------------------------------\n",
      "[100.00%] Total execution time:  15.300 s   number of results: 3\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "import taichi as ti\n",
    "\n",
    "ti.init(arch=ti.cpu, kernel_profiler=True)\n",
    "\n",
    "n = 64 * 1024 * 1024\n",
    "dim = 4\n",
    "unroll = 8\n",
    "\n",
    "a = ti.Vector.field(dim, dtype=ti.i32, shape=n, \n",
    "                    layout=ti.Layout.SOA)\n",
    "\n",
    "@ti.kernel\n",
    "def assign_all():\n",
    "    for i in range(n):\n",
    "        for k in ti.static(range(dim)):\n",
    "            a[i][k] = i + k\n",
    "            \n",
    "@ti.kernel\n",
    "def assign_single():\n",
    "    for i in range(n):\n",
    "        a[i][0] = i\n",
    "            \n",
    "@ti.kernel\n",
    "def assign_all_random():\n",
    "    for i_ in range(n):\n",
    "        for k in ti.static(range(dim)):\n",
    "            i = (i_ * 10007) & (n - 1) # Random index\n",
    "            a[i][k] = i + k\n",
    "    \n",
    "for repeat in range(30):\n",
    "    assign_all()\n",
    "\n",
    "\n",
    "for repeat in range(30):\n",
    "    assign_single()\n",
    "\n",
    "    \n",
    "for repeat in range(30):\n",
    "    assign_all_random()\n",
    "\n",
    "    \n",
    "ti.profiler.print_kernel_profiler_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d498c",
   "metadata": {},
   "source": [
    "|  Times(s)   | assign_all  | assign_single | assigen_all_random |\n",
    "|  ----  | ---- | ---- | ---- | \n",
    "| AOS  | 0.68 | 0.61 | 8.37 |\n",
    "| SOA  | 0.70 | 0.48 | 14.37 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42e572",
   "metadata": {},
   "source": [
    "1. 不论是何种布局，顺序访问都比随机访问快。\n",
    "2. assign_single任务下，SOA的性能要优于AOS\n",
    "3. 如果你的访问是顺序访问，那么 SOA 通常比 AOS 效率高一些。特别是当你的程序在 GPU 上运行的时候，因为 Coalescing。\n",
    "4. 如果你的访问是随机访问，那么 AOS 常常比 SOA 更好。因为随机访问的一个粒子的数据在 AOS 下是在同一个 cacheline 中，而在 SOA 布局下会分散在 4 个 cachelines 里面，对于 AOS 的 cacheline utilization（缓存行利用率）会高很多。比如在上面的例子中，assign_all_random 在 AOS 布局下就比 SOA 快了近 2 倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d1b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:taichi]",
   "language": "python",
   "name": "conda-env-taichi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
